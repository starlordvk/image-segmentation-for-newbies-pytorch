{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Images in train dataset =  2975\n",
      "Total Images in val dataset =  500\n",
      "Total Images in test dataset =  1525\n",
      "Shape of image =  torch.Size([32, 3, 1024, 2048])\n",
      "Shape of smnt =  torch.Size([32, 4, 1024, 2048])\n",
      "Shape of image =  torch.Size([32, 3, 1024, 2048])\n",
      "Shape of smnt =  torch.Size([32, 4, 1024, 2048])\n",
      "Shape of image =  torch.Size([32, 3, 1024, 2048])\n",
      "Shape of smnt =  torch.Size([32, 4, 1024, 2048])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import os.path as osp\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from datasets.cityscapes import trainDataset, valDataset, testDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device =  cuda\n"
     ]
    }
   ],
   "source": [
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Device = \", DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Images in train dataset =  2975\n",
      "Total Images in val dataset =  500\n",
      "Total Images in test dataset =  1525\n",
      "Shape of image =  torch.Size([32, 3, 1024, 2048])\n",
      "Shape of smnt =  torch.Size([32, 4, 1024, 2048])\n",
      "Shape of image =  torch.Size([32, 3, 1024, 2048])\n",
      "Shape of smnt =  torch.Size([32, 4, 1024, 2048])\n",
      "Shape of image =  torch.Size([32, 3, 1024, 2048])\n",
      "Shape of smnt =  torch.Size([32, 4, 1024, 2048])\n"
     ]
    }
   ],
   "source": [
    "train_dataloader = DataLoader(trainDataset, shuffle = True, batch_size = 32)\n",
    "test_dataloader = DataLoader(valDataset, shuffle = True, batch_size = 32)\n",
    "val_dataloader = DataLoader(testDataset, shuffle = True, batch_size = 32)\n",
    "\n",
    "for i, (img, smnt) in enumerate(train_dataloader):\n",
    "    print(\"Shape of image = \", img.shape)\n",
    "    print(\"Shape of smnt = \", smnt.shape)\n",
    "\n",
    "    if i == 2:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Double convolution block.\n",
    "class Conv2x_Block(torch.nn.Module):\n",
    "    def __init__(self, inChannelCount, outChannelCount):\n",
    "        super().__init__()\n",
    "        conv2x = nn.Sequential(\n",
    "            # Remove bias if adding batchnorm later.\n",
    "            nn.Conv2d(inChannelCount, outChannelCount, kernel_size=3, stride=1, bias=True),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(outChannelCount, outChannelCount, kernel_size=3, stride=1, bias=True),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "    def forward(self, X):\n",
    "        return self.conv2x(X)\n",
    "\n",
    "class UNet_Encoder(torch.nn.Module):\n",
    "    def __init__(self, channels_per_layer=[3, 64, 128, 256, 512]):\n",
    "        super().__init__()\n",
    "        self.encoder_conv2x = torch.nn.ModuleList(\n",
    "            [Conv2x_Block(channels_per_layer[i], channels_per_layer[i+1]) for i in range(0, len(channels_per_layer) - 1)]\n",
    "        )\n",
    "        self.max_pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "    \n",
    "    def forward(self, X):\n",
    "        self.residual_layers_output = []\n",
    "        for conv_block in self.EncoderConv2x:\n",
    "            X = conv_block(X)\n",
    "            self.residual_layers_output.append(X)\n",
    "            X = self.max_pool(X)\n",
    "        \n",
    "        return X, self.residual_layers_output\n",
    "\n",
    "\n",
    "class UNet_Decoder(torch.nn.Module):\n",
    "    def __init__(self, channels_per_layer=[512, 256, 128, 64]):\n",
    "        super().__init__()\n",
    "        self.channels_per_layer = channels_per_layer\n",
    "        self.transpose_conv = torch.nn.ModuleList(\n",
    "\t\t\t[nn.ConvTranspose2d(channels_per_layer[i], channels_per_layer[i + 1], kernel_size=2, stride=2) for i in range(0, len(channels_per_layer) - 1)])\n",
    "\t\t\t \t\n",
    "        self.decoder_conv2x = torch.nn.ModuleList(\n",
    "            [Conv2x_Block(channels_per_layer[i], channels_per_layer[i+1]) for i in range(0, len(channels_per_layer) - 1)]\n",
    "        )\n",
    "        \n",
    "        #self.max_pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "    def forward(self, X, encoder_layers_output):\n",
    "        for trans_conv,  conv2x, encoder_layer in zip(self.transpose_conv, self.decoder_conv2x, encoder_layers_output):\n",
    "            X = trans_conv(X)\n",
    "            if X.shape != encoder_layer.shape:\n",
    "                X = transforms.functional.resize(X, encoder_layer.shape[2:])\n",
    "\n",
    "            X_concatenated = torch.cat((encoder_layer, X), dim = 1)\n",
    "            X = conv2x(X_concatenated)\n",
    "        return X\n",
    "\n",
    "class UNet(torch.nn.Module):\n",
    "    def __init__(self, encoder_channels, decoder_channels):\n",
    "          super().__init__()\n",
    "          self.encoder = UNet_Encoder(encoder_channels)\n",
    "          self.decoder = UNet_Encoder(decoder_channels)\n",
    "          self.final_conv = nn.Conv2d(decoder_channels[-1], num_classes=19, kernel_size=1)\n",
    "\n",
    "    def forward(self, X):\n",
    "        X_encoded, encoder_layers_output = self.encoder(X)\n",
    "        X_decoded = self.decoder(X_encoded, encoder_layers_output[::-1])\n",
    "        out = self.final_conv(X_decoded)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "fc1c17ed6e82574d955cd1964c72537b0ce70623a76e49c79653b7a660047c1d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
